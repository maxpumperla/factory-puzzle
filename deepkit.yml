image: python:3.7

build:
  - ADD requirements.txt
  - pip install -r requirements.txt
  - ADD factory/
  - ADD setup.py
  - python setup.py install

#env:
#  - PYTHONPATH=/job

output:
  - DQN
  - PPO

ignore:
  - DQN
  - PPO
  - models
  - tests
  - assets
  - venv
  - .pytest_cache

title: Factory solver
list: test-experiment
labels:
  - rllib
  - tensorflow

config:
  # Fixed settings
  env_name: factory
  actions: 5
  low: -1
  high: 10

  # Factory settings
  layout: small
  num_tables: 1
  num_cores: 1
  num_phases: 3
  random_init: True
#  seed: 1337

  # Logging & Tracking
  deepkit_logging: True
  deepkit_account: deepkit # or localhost

  # RL-specific configuration
  env: MultiAgentFactoryEnv  # "FactoryEnv", "RoundRobinFactoryEnv", "MultiAgentFactoryEnv"
  max_num_steps: 5000 # NOTE: need to set this high enough for the big factory
  masking: True
  use_dqn: True
  use_offline_data: False
  num_samples: 4
  multi_policy: False # Note: this only work for "MultiAgentEnv"

  ## Neighbour obs
  obs_agent_has_neighbour: False
  obs_agent_free_neighbour: True

  ## Agent & core obs
  obs_agent_id: True
  obs_agent_coordinates: True

  obs_agent_has_core: True
  obs_agent_core_target_coordinates: True

  ## One-hot representation obs
  obs_agent_id_one_hot: False
  obs_agent_core_target_one_hot: False
  obs_all_tables_one_hot: False


  # does not make much sense
  obs_all_cores_one_hot: False


command: python examples/save_trainer.py
